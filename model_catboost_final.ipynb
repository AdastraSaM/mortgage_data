{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterization\n",
    "\n",
    "# Prototyping\n",
    "sample_size = 1\n",
    "\n",
    "# dropnan\n",
    "do_dropallnan = 0\n",
    "\n",
    "# Outliers\n",
    "do_drop_outliers = 1\n",
    "\n",
    "# one-hot encoding?\n",
    "do_one_hot = 0\n",
    "\n",
    "# PCA\n",
    "do_pca = \"none\"\n",
    "pca_n_components = 5\n",
    "\n",
    "# Scaling\n",
    "do_normalization = 0\n",
    "\n",
    "# Imputation\n",
    "imputation = \"drop\"\n",
    "\n",
    "# Feature Selection\n",
    "do_select_percentile = 0\n",
    "select_percentile_percentile = 25\n",
    "\n",
    "do_selectkbest = 1\n",
    "selectkbest_k = 20\n",
    "\n",
    "# Machine Learning\n",
    "do_xgb = 0\n",
    "\n",
    "# evaluation on test set\n",
    "do_evaluate = 0\n",
    "\n",
    "# scoring\n",
    "do_scoring = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, mutual_info_classif, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "from time import time\n",
    "from catboost import CatBoostClassifier\n",
    "#import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from files\n",
    "\n",
    "X_in = pd.read_csv('../Data/X_binned.csv')\n",
    "Y_in = pd.read_csv('../Data/train_labels.csv')\n",
    "\n",
    "\n",
    "# score set\n",
    "X_score = pd.read_csv('../Data/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_in)\n",
    "data = data.merge(Y_in, on='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"LoanIncomeRatio\"]=data[\"loan_amount\"]/data[\"applicant_income\"]\n",
    "X_score[\"LoanIncomeRatio\"]=X_score[\"loan_amount\"]/X_score[\"applicant_income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only these columns are really numeric. The others are already label encoded as numbers\n",
    "num_cols = [\n",
    "    \"loan_amount\",\n",
    "    \"applicant_income\",\n",
    "    \"population\",\n",
    "    \"minority_population_pct\",\n",
    "    \"ffiecmedian_family_income\",\n",
    "    \"tract_to_msa_md_income_pct\",\n",
    "    \"number_of_owner-occupied_units\",\n",
    "    \"number_of_1_to_4_family_units\",\n",
    "    \"loan_amount\",\n",
    "    \"LoanIncomeRatio\"\n",
    "]\n",
    "print(\"Numeric columns: \")\n",
    "print(num_cols)\n",
    "\n",
    "cat_cols = list(set(data.columns) - set(num_cols)-set([\"accepted\", \"row_id\"]))\n",
    "print(\"Categorical columns: \")\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual feature selection\n",
    "drop_features = [\n",
    "    'row_id'\n",
    "    #'loan_amount',\n",
    "    #'applicant_income',\n",
    "    #'population',\n",
    "    #'minority_population_pct',\n",
    "    #'ffiecmedian_family_income',\n",
    "    #'tract_to_msa_md_income_pct',\n",
    "    #'number_of_owner-occupied_units',\n",
    "    #'number_of_1_to_4_family_units',\n",
    "    #cat\n",
    "    #'occupancy',\n",
    "    #'preapproval',\n",
    "    #'state_code',\n",
    "    #'county_code',\n",
    "    #'property_type',\n",
    "    #'applicant_race',\n",
    "    #'loan_purpose',\n",
    "    #'lender',\n",
    "    #'applicant_ethnicity'\n",
    "    #'applicant_sex',\n",
    "    #'loan_type',\n",
    "    #'co_applicant',\n",
    "    #'msa_md'\n",
    "]\n",
    "# Update list of numeric and categorical columns\n",
    "num_cols = list(set(num_cols) - set(drop_features) - set([\"row_id\"]))\n",
    "cat_cols = list(set(cat_cols) - set(drop_features))\n",
    "\n",
    "# Drop features from data\n",
    "data.drop(drop_features, axis=1, inplace=True)\n",
    "X_score.drop(drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining numeric columns\")\n",
    "print(num_cols)\n",
    "print(\"Remaining categorical columns\")\n",
    "print(cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "def dropoutliers(data):\n",
    "    if do_drop_outliers == 1:\n",
    "        if \"loan_amout\" in data.columns:\n",
    "            data.drop(data[data[\"loan_amount\"]>700].index, inplace=True)\n",
    "        if \"applicant_income\" in data.columns:       \n",
    "            data.drop(data[data[\"applicant_income\"]>200].index, inplace=True)\n",
    "        if \"population\" in data.columns:\n",
    "            data.drop(data[data[\"population\"]>190000].index, inplace=True)\n",
    "        if \"ffiecmedian_family_income\" in data.columns:\n",
    "            data.drop(data[data[\"ffiecmedian_family_income\"]<20000].index, inplace=True)\n",
    "        if \"ffiecmedian_family_income\" in data.columns:\n",
    "            data.drop(data[data[\"ffiecmedian_family_income\"]>120000].index, inplace=True)\n",
    "        if \"tract_to_msa_md_income_pct\" in data.columns:\n",
    "            data.drop(data[data[\"tract_to_msa_md_income_pct\"]<40].index, inplace=True)        \n",
    "        if \"number_of_1_to_4_family_units\" in data.columns:\n",
    "            data.drop(data[data[\"number_of_1_to_4_family_units\"]>6000].index, inplace=True)\n",
    "        if \"number_of_owner-occupied_units\" in data.columns:\n",
    "            data.drop(data[data[\"number_of_owner-occupied_units\"]>4500].index, inplace=True)\n",
    "        if \"LoanIncomeRatio\" in data.columns:\n",
    "            data.drop(data[data[\"LoanIncomeRatio\"]>15].index, inplace=True)\n",
    "\n",
    "        print(\"Dropped outliers\")\n",
    "        return data\n",
    "\n",
    "data = dropoutliers(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and Y\n",
    "feature_cols = [col for col in data.columns ]\n",
    "X = pd.DataFrame(data.loc[:, data.columns != \"accepted\"])\n",
    "Y = data[\"accepted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all nans\n",
    "if do_dropallnan == 1:\n",
    "    data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat missing values\n",
    "data.replace({-1: np.nan}, inplace=True)\n",
    "X_score.replace({-1: np.nan}, inplace=True)\n",
    "\n",
    "if imputation == \"drop\":\n",
    "    data.dropna(inplace=True)\n",
    "    X_score.dropna(inplace=True)\n",
    "    \n",
    "if imputation == \"median\":\n",
    "    for col in X.columns:\n",
    "        col_median = X[col].median()\n",
    "        X[col] = X[col].replace({np.nan: col_median})\n",
    "        X_score[col] = X_score[col].replace({np.nan: col_median})\n",
    "        \n",
    "if imputation == \"mean\":\n",
    "    for col in X.columns:\n",
    "        col_mean = X[col].mean()\n",
    "        X[col] = X[col].replace({np.nan: col_mean})\n",
    "        X_score[col] = X_score[col].replace({np.nan: col_mean})        \n",
    "\n",
    "if imputation == \"fixed\":\n",
    "        for col in X.columns:\n",
    "            fixed_val = -1\n",
    "            X[col] = X[col].replace({np.nan: fixed_val})\n",
    "            X_score[col] = X_score[col].replace({np.nan: fixed_val})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "if (do_normalization == 1) and (num_cols != []):\n",
    "    print(\"Standardizing data...\")\n",
    "    scaler = StandardScaler()\n",
    "    X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "    X_score[num_cols] = scaler.fit_transform(X_score[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "# 80% train, 20% test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_cat = CatBoostClassifier(learning_rate=0.05,\n",
    "                            n_estimators=200,\n",
    "                            eval_metric='Accuracy',\n",
    "                            one_hot_max_size=5,\n",
    "                            max_depth=6,\n",
    "                            random_strength=10\n",
    "                            )\n",
    "clf_cat.fit(X_train, Y_train, plot=True, logging_level='Silent', eval_set=(X_test.values, Y_test.values))\n",
    "Y_pred = clf_cat.predict(X_test)\n",
    "Y_pred_train = clf_cat.predict(X_train)\n",
    "test_acc = accuracy_score(Y_test, Y_pred)\n",
    "train_acc = accuracy_score(Y_train, Y_pred_train)\n",
    "print(\"Accuracy on test set: \" + str(test_acc))\n",
    "print(\"Accuracy on train set: \" + str(train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({'imp': clf_cat.feature_importances_, 'col': clf_cat.feature_names_})\n",
    "fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False])\n",
    "fea_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# explain the model's predictions using SHAP values\n",
    "# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\n",
    "explainer = shap.TreeExplainer(clf_cat)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict score set\n",
    "Y_score = clf_cat.predict(X_score)\n",
    "Y_score = Y_score.astype(int)\n",
    "out = pd.DataFrame()\n",
    "out[\"row_id\"] = X_score.index.values\n",
    "out[\"accepted\"] = Y_score\n",
    "\n",
    "out.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
