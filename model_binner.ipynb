{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from files\n",
    "X_in = pd.read_csv('../Data/train_values.csv')\n",
    "Y_in = pd.read_csv('../Data/train_labels.csv')\n",
    "\n",
    "\n",
    "# score set\n",
    "X_score = pd.read_csv('../Data/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_in)\n",
    "data = data.merge(Y_in, on='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Markus.Haftstein.ADASTRACORPNET\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    }
   ],
   "source": [
    "# lender\n",
    "# 6111 distinct values\n",
    "lenders_data = data[[\"lender\", \"accepted\"]].groupby(by=\"lender\").sum() / data[[\"lender\", \"accepted\"]].groupby(by=\"lender\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal')\n",
    "\n",
    "lenders_binned = discretizer.fit_transform(lenders_data)\n",
    "lenders_data[\"lender_bin\"] = lenders_binned\n",
    "\n",
    "lenders_dict = lenders_data[\"lender_bin\"].to_dict()\n",
    "\n",
    "data[\"lender\"].replace(lenders_dict, inplace=True)\n",
    "X_score[\"lender\"].replace(lenders_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_code\n",
    "# 318 distinct values\n",
    "county_data = data[[\"county_code\", \"accepted\"]].groupby(by=\"county_code\").sum() / data[[\"county_code\", \"accepted\"]].groupby(by=\"county_code\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal')\n",
    "\n",
    "county_binned = discretizer.fit_transform(county_data)\n",
    "county_data[\"county_bin\"] = county_binned\n",
    "\n",
    "county_dict = county_data[\"county_bin\"].to_dict()\n",
    "\n",
    "data[\"county_code\"].replace(county_dict, inplace=True)\n",
    "X_score[\"county_code\"].replace(county_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_code\n",
    "# 53 distinct values\n",
    "state_data = data[[\"state_code\", \"accepted\"]].groupby(by=\"state_code\").sum() / data[[\"state_code\", \"accepted\"]].groupby(by=\"state_code\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal')\n",
    "\n",
    "state_binned = discretizer.fit_transform(state_data)\n",
    "state_data[\"state_bin\"] = state_binned\n",
    "\n",
    "state_dict = state_data[\"state_bin\"].to_dict()\n",
    "\n",
    "data[\"state_code\"].replace(state_dict, inplace=True)\n",
    "X_score[\"state_code\"].replace(state_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msa_md\n",
    "# 409 distinct values\n",
    "msa_md_data = data[[\"msa_md\", \"accepted\"]].groupby(by=\"msa_md\").sum() / data[[\"msa_md\", \"accepted\"]].groupby(by=\"msa_md\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=6, encode='ordinal')\n",
    "\n",
    "msa_md_binned = discretizer.fit_transform(msa_md_data)\n",
    "msa_md_data[\"msa_md_bin\"] = msa_md_binned\n",
    "\n",
    "msa_md_dict = msa_md_data[\"msa_md_bin\"].to_dict()\n",
    "\n",
    "data[\"msa_md\"].replace(msa_md_dict, inplace=True)\n",
    "X_score[\"msa_md\"].replace(msa_md_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_purpose\n",
    "# 3 distinct values\n",
    "lp_data = data[[\"loan_purpose\", \"accepted\"]].groupby(by=\"loan_purpose\").sum() / data[[\"loan_purpose\", \"accepted\"]].groupby(by=\"loan_purpose\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal')\n",
    "\n",
    "lp_binned = discretizer.fit_transform(lp_data)\n",
    "lp_data[\"loan_purpose_bin\"] = lp_binned\n",
    "\n",
    "lp_dict = lp_data[\"loan_purpose_bin\"].to_dict()\n",
    "\n",
    "data[\"loan_purpose\"].replace(lp_dict, inplace=True)\n",
    "X_score[\"loan_purpose\"].replace(lp_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_race\n",
    "# 7 distinct values\n",
    "applicant_race_data = data[[\"applicant_race\", \"accepted\"]].groupby(by=\"applicant_race\").sum() / data[[\"applicant_race\", \"accepted\"]].groupby(by=\"applicant_race\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=7, encode='ordinal')\n",
    "\n",
    "applicant_race_binned = discretizer.fit_transform(applicant_race_data)\n",
    "applicant_race_data[\"applicant_race_bin\"] = applicant_race_binned\n",
    "\n",
    "applicant_race_dict = applicant_race_data[\"applicant_race_bin\"].to_dict()\n",
    "\n",
    "data[\"applicant_race\"].replace(applicant_race_dict, inplace=True)\n",
    "X_score[\"applicant_race\"].replace(applicant_race_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_type\n",
    "# 3 distinct values\n",
    "property_type_data = data[[\"property_type\", \"accepted\"]].groupby(by=\"property_type\").sum() / data[[\"property_type\", \"accepted\"]].groupby(by=\"property_type\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal')\n",
    "\n",
    "property_type_binned = discretizer.fit_transform(property_type_data)\n",
    "property_type_data[\"property_type_bin\"] = property_type_binned\n",
    "\n",
    "property_type_dict = property_type_data[\"property_type_bin\"].to_dict()\n",
    "\n",
    "data[\"property_type\"].replace(property_type_dict, inplace=True)\n",
    "X_score[\"property_type\"].replace(property_type_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant_ethnicity\n",
    "# 4 distinct values\n",
    "applicant_ethnicity_data = data[[\"applicant_ethnicity\", \"accepted\"]].groupby(by=\"applicant_ethnicity\").sum() / data[[\"applicant_ethnicity\", \"accepted\"]].groupby(by=\"applicant_ethnicity\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal')\n",
    "\n",
    "applicant_ethnicity_binned = discretizer.fit_transform(applicant_ethnicity_data)\n",
    "applicant_ethnicity_data[\"applicant_ethnicity_bin\"] = applicant_ethnicity_binned\n",
    "\n",
    "applicant_ethnicity_dict = applicant_ethnicity_data[\"applicant_ethnicity_bin\"].to_dict()\n",
    "\n",
    "data[\"applicant_ethnicity\"].replace(applicant_ethnicity_dict, inplace=True)\n",
    "X_score[\"applicant_ethnicity\"].replace(applicant_ethnicity_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_type\n",
    "# 4 distinct values\n",
    "loan_type_data = data[[\"loan_type\", \"accepted\"]].groupby(by=\"loan_type\").sum() / data[[\"loan_type\", \"accepted\"]].groupby(by=\"loan_type\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal')\n",
    "\n",
    "loan_type_binned = discretizer.fit_transform(loan_type_data)\n",
    "loan_type_data[\"loan_type_bin\"] = loan_type_binned\n",
    "\n",
    "loan_type_dict = loan_type_data[\"loan_type_bin\"].to_dict()\n",
    "\n",
    "data[\"loan_type\"].replace(loan_type_dict, inplace=True)\n",
    "X_score[\"loan_type\"].replace(loan_type_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occupancy\n",
    "# 3 distinct values\n",
    "occupancy_data = data[[\"occupancy\", \"accepted\"]].groupby(by=\"occupancy\").sum() / data[[\"occupancy\", \"accepted\"]].groupby(by=\"occupancy\").count()\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal')\n",
    "\n",
    "occupancy_binned = discretizer.fit_transform(occupancy_data)\n",
    "occupancy_data[\"occupancy_bin\"] = occupancy_binned\n",
    "\n",
    "occupancy_dict = occupancy_data[\"occupancy_bin\"].to_dict()\n",
    "\n",
    "data[\"occupancy\"].replace(occupancy_dict, inplace=True)\n",
    "X_score[\"occupancy\"].replace(occupancy_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"LoanIncomeRatio\"]=data[\"loan_amount\"]/data[\"applicant_income\"]\n",
    "X_score[\"LoanIncomeRatio\"]=X_score[\"loan_amount\"]/X_score[\"applicant_income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"accepted\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"X_binned.csv\")\n",
    "X_score.to_csv(\"X_score_binned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
